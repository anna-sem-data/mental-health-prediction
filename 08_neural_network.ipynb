{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0621b56-0bf4-4588-90f6-f2061a81f468",
   "metadata": {},
   "source": [
    "# Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc05dea-a690-47b6-8680-132a69322955",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcc22721-38aa-41b2-be35-2125c5c49d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 0.9407 - Train Acc: 0.6992 - Test Acc: 0.7100\n",
      "Epoch 2/50 - Loss: 0.8763 - Train Acc: 0.7089 - Test Acc: 0.7100\n",
      "Epoch 3/50 - Loss: 0.8669 - Train Acc: 0.7090 - Test Acc: 0.7100\n",
      "Epoch 4/50 - Loss: 0.8614 - Train Acc: 0.7091 - Test Acc: 0.7100\n",
      "Epoch 5/50 - Loss: 0.8553 - Train Acc: 0.7085 - Test Acc: 0.7100\n",
      "Epoch 6/50 - Loss: 0.8554 - Train Acc: 0.7092 - Test Acc: 0.7100\n",
      "Epoch 7/50 - Loss: 0.8521 - Train Acc: 0.7086 - Test Acc: 0.7100\n",
      "Epoch 8/50 - Loss: 0.8513 - Train Acc: 0.7088 - Test Acc: 0.7101\n",
      "Epoch 9/50 - Loss: 0.8480 - Train Acc: 0.7090 - Test Acc: 0.7100\n",
      "Epoch 10/50 - Loss: 0.8459 - Train Acc: 0.7082 - Test Acc: 0.7099\n",
      "Epoch 11/50 - Loss: 0.8443 - Train Acc: 0.7088 - Test Acc: 0.7100\n",
      "Epoch 12/50 - Loss: 0.8442 - Train Acc: 0.7082 - Test Acc: 0.7100\n",
      "Epoch 13/50 - Loss: 0.8442 - Train Acc: 0.7087 - Test Acc: 0.7100\n",
      "Epoch 14/50 - Loss: 0.8436 - Train Acc: 0.7093 - Test Acc: 0.7078\n",
      "Epoch 15/50 - Loss: 0.8434 - Train Acc: 0.7086 - Test Acc: 0.7100\n",
      "Epoch 16/50 - Loss: 0.8409 - Train Acc: 0.7088 - Test Acc: 0.7088\n",
      "Epoch 17/50 - Loss: 0.8401 - Train Acc: 0.7093 - Test Acc: 0.7100\n",
      "Epoch 18/50 - Loss: 0.8410 - Train Acc: 0.7086 - Test Acc: 0.7100\n",
      "Epoch 19/50 - Loss: 0.8411 - Train Acc: 0.7087 - Test Acc: 0.7100\n",
      "Epoch 20/50 - Loss: 0.8402 - Train Acc: 0.7085 - Test Acc: 0.7100\n",
      "Epoch 21/50 - Loss: 0.8398 - Train Acc: 0.7085 - Test Acc: 0.7100\n",
      "Epoch 22/50 - Loss: 0.8395 - Train Acc: 0.7078 - Test Acc: 0.7100\n",
      "Epoch 23/50 - Loss: 0.8380 - Train Acc: 0.7078 - Test Acc: 0.7098\n",
      "Epoch 24/50 - Loss: 0.8374 - Train Acc: 0.7085 - Test Acc: 0.7100\n",
      "Epoch 25/50 - Loss: 0.8379 - Train Acc: 0.7082 - Test Acc: 0.7098\n",
      "Epoch 26/50 - Loss: 0.8380 - Train Acc: 0.7084 - Test Acc: 0.7100\n",
      "Epoch 27/50 - Loss: 0.8383 - Train Acc: 0.7090 - Test Acc: 0.7100\n",
      "Epoch 28/50 - Loss: 0.8377 - Train Acc: 0.7086 - Test Acc: 0.7102\n",
      "Epoch 29/50 - Loss: 0.8365 - Train Acc: 0.7084 - Test Acc: 0.7100\n",
      "Epoch 30/50 - Loss: 0.8356 - Train Acc: 0.7096 - Test Acc: 0.7100\n",
      "Epoch 31/50 - Loss: 0.8384 - Train Acc: 0.7088 - Test Acc: 0.7101\n",
      "Epoch 32/50 - Loss: 0.8356 - Train Acc: 0.7086 - Test Acc: 0.7101\n",
      "Epoch 33/50 - Loss: 0.8360 - Train Acc: 0.7090 - Test Acc: 0.7103\n",
      "Epoch 34/50 - Loss: 0.8361 - Train Acc: 0.7089 - Test Acc: 0.7100\n",
      "Epoch 35/50 - Loss: 0.8361 - Train Acc: 0.7085 - Test Acc: 0.7099\n",
      "Epoch 36/50 - Loss: 0.8368 - Train Acc: 0.7085 - Test Acc: 0.7100\n",
      "Epoch 37/50 - Loss: 0.8350 - Train Acc: 0.7085 - Test Acc: 0.7103\n",
      "Epoch 38/50 - Loss: 0.8346 - Train Acc: 0.7084 - Test Acc: 0.7100\n",
      "Epoch 39/50 - Loss: 0.8344 - Train Acc: 0.7081 - Test Acc: 0.7099\n",
      "Epoch 40/50 - Loss: 0.8350 - Train Acc: 0.7080 - Test Acc: 0.7094\n",
      "Epoch 41/50 - Loss: 0.8361 - Train Acc: 0.7091 - Test Acc: 0.7100\n",
      "Epoch 42/50 - Loss: 0.8352 - Train Acc: 0.7083 - Test Acc: 0.7100\n",
      "Epoch 43/50 - Loss: 0.8345 - Train Acc: 0.7085 - Test Acc: 0.7102\n",
      "Epoch 44/50 - Loss: 0.8352 - Train Acc: 0.7089 - Test Acc: 0.7100\n",
      "Epoch 45/50 - Loss: 0.8350 - Train Acc: 0.7088 - Test Acc: 0.7098\n",
      "Epoch 46/50 - Loss: 0.8345 - Train Acc: 0.7081 - Test Acc: 0.7100\n",
      "Epoch 47/50 - Loss: 0.8331 - Train Acc: 0.7091 - Test Acc: 0.7103\n",
      "Epoch 48/50 - Loss: 0.8345 - Train Acc: 0.7083 - Test Acc: 0.7100\n",
      "Epoch 49/50 - Loss: 0.8333 - Train Acc: 0.7080 - Test Acc: 0.7102\n",
      "Epoch 50/50 - Loss: 0.8345 - Train Acc: 0.7081 - Test Acc: 0.7099\n",
      "\n",
      "Final Test Accuracy: 0.7099\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Uncertain       0.71      1.00      0.83      6553\n",
      "       anger       0.00      0.00      0.00       167\n",
      "     disgust       0.00      0.00      0.00         9\n",
      "        fear       0.00      0.00      0.00       668\n",
      "         joy       0.00      0.00      0.00       232\n",
      "     neutral       0.00      0.00      0.00        12\n",
      "     sadness       0.00      0.00      0.00      1520\n",
      "    surprise       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.71      9230\n",
      "   macro avg       0.09      0.12      0.10      9230\n",
      "weighted avg       0.50      0.71      0.59      9230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "data = pd.read_csv('emotion_data.csv')\n",
    "target_col = 'predicted_emotion'\n",
    "feature_cols = [\n",
    "    'sentiment_score', 'text_length', 'word_count', \n",
    "    'avg_word_length', 'stopword_count', \n",
    "    'first_person_pronoun_count', 'keyword_count'\n",
    "]\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[target_col]\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader objects for batch training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 2. Define the Neural Network Model using PyTorch\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "model = MLP(input_dim, num_classes)\n",
    "\n",
    "# 3. Define Loss, Optimizer, and Training Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "# 4. Training the Model with Epoch-by-Epoch Accuracy Monitoring\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "    \n",
    "    # Evaluate test accuracy\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "    test_acc = correct_test / total_test\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# 5. Final Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {np.mean(np.array(all_preds) == y_test):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1c84f1-f94d-4aa8-ab6f-15dd823440fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "   sentiment_score  text_length  word_count  avg_word_length  stopword_count  \\\n",
      "0           0.0000           10           3                3               1   \n",
      "1          -0.7269           61          10                6               3   \n",
      "2          -0.7351           75          14                5               5   \n",
      "3          -0.4215           59          11                5               3   \n",
      "4          -0.4939           66          14                4               8   \n",
      "\n",
      "   first_person_pronoun_count  keyword_count  \n",
      "0                           1              0  \n",
      "1                           0              0  \n",
      "2                           0              0  \n",
      "3                           1              0  \n",
      "4                           0              0  \n",
      "\n",
      "Target Variable:\n",
      "0     surprise\n",
      "1         fear\n",
      "2         fear\n",
      "3    Uncertain\n",
      "4         fear\n",
      "Name: predicted_emotion, dtype: object\n",
      "Epoch 1/50 - Loss: 0.9041 - Train Acc: 0.7057 - Test Acc: 0.7100\n",
      "Epoch 2/50 - Loss: 0.8587 - Train Acc: 0.7089 - Test Acc: 0.7100\n",
      "Epoch 3/50 - Loss: 0.8530 - Train Acc: 0.7091 - Test Acc: 0.7100\n",
      "Epoch 4/50 - Loss: 0.8506 - Train Acc: 0.7091 - Test Acc: 0.7100\n",
      "Epoch 5/50 - Loss: 0.8468 - Train Acc: 0.7090 - Test Acc: 0.7100\n",
      "Epoch 6/50 - Loss: 0.8447 - Train Acc: 0.7091 - Test Acc: 0.7099\n",
      "Epoch 7/50 - Loss: 0.8445 - Train Acc: 0.7088 - Test Acc: 0.7100\n",
      "Epoch 8/50 - Loss: 0.8417 - Train Acc: 0.7090 - Test Acc: 0.7100\n",
      "Epoch 9/50 - Loss: 0.8418 - Train Acc: 0.7090 - Test Acc: 0.7100\n",
      "Epoch 10/50 - Loss: 0.8393 - Train Acc: 0.7088 - Test Acc: 0.7100\n",
      "Epoch 11/50 - Loss: 0.8384 - Train Acc: 0.7088 - Test Acc: 0.7100\n",
      "Epoch 12/50 - Loss: 0.8361 - Train Acc: 0.7092 - Test Acc: 0.7100\n",
      "Epoch 13/50 - Loss: 0.8364 - Train Acc: 0.7090 - Test Acc: 0.7100\n",
      "Epoch 14/50 - Loss: 0.8341 - Train Acc: 0.7087 - Test Acc: 0.7100\n",
      "Epoch 15/50 - Loss: 0.8353 - Train Acc: 0.7088 - Test Acc: 0.7100\n",
      "Epoch 16/50 - Loss: 0.8324 - Train Acc: 0.7088 - Test Acc: 0.7100\n",
      "Epoch 17/50 - Loss: 0.8327 - Train Acc: 0.7089 - Test Acc: 0.7100\n",
      "Epoch 18/50 - Loss: 0.8325 - Train Acc: 0.7091 - Test Acc: 0.7100\n",
      "Epoch 19/50 - Loss: 0.8311 - Train Acc: 0.7091 - Test Acc: 0.7099\n",
      "Epoch 20/50 - Loss: 0.8314 - Train Acc: 0.7087 - Test Acc: 0.7100\n",
      "Epoch 21/50 - Loss: 0.8298 - Train Acc: 0.7086 - Test Acc: 0.7100\n",
      "Epoch 22/50 - Loss: 0.8295 - Train Acc: 0.7093 - Test Acc: 0.7100\n",
      "Epoch 23/50 - Loss: 0.8300 - Train Acc: 0.7085 - Test Acc: 0.7100\n",
      "Epoch 24/50 - Loss: 0.8284 - Train Acc: 0.7086 - Test Acc: 0.7100\n",
      "Epoch 25/50 - Loss: 0.8274 - Train Acc: 0.7087 - Test Acc: 0.7100\n",
      "Epoch 26/50 - Loss: 0.8276 - Train Acc: 0.7093 - Test Acc: 0.7100\n",
      "Epoch 27/50 - Loss: 0.8278 - Train Acc: 0.7084 - Test Acc: 0.7100\n",
      "Epoch 28/50 - Loss: 0.8275 - Train Acc: 0.7085 - Test Acc: 0.7100\n",
      "Epoch 29/50 - Loss: 0.8260 - Train Acc: 0.7080 - Test Acc: 0.7100\n",
      "Epoch 30/50 - Loss: 0.8252 - Train Acc: 0.7082 - Test Acc: 0.7102\n",
      "Epoch 31/50 - Loss: 0.8252 - Train Acc: 0.7089 - Test Acc: 0.7100\n",
      "Epoch 32/50 - Loss: 0.8249 - Train Acc: 0.7091 - Test Acc: 0.7100\n",
      "Epoch 33/50 - Loss: 0.8246 - Train Acc: 0.7086 - Test Acc: 0.7106\n",
      "Epoch 34/50 - Loss: 0.8245 - Train Acc: 0.7088 - Test Acc: 0.7098\n",
      "Epoch 35/50 - Loss: 0.8244 - Train Acc: 0.7086 - Test Acc: 0.7100\n",
      "Epoch 36/50 - Loss: 0.8243 - Train Acc: 0.7087 - Test Acc: 0.7100\n",
      "Epoch 37/50 - Loss: 0.8231 - Train Acc: 0.7089 - Test Acc: 0.7100\n",
      "Epoch 38/50 - Loss: 0.8226 - Train Acc: 0.7089 - Test Acc: 0.7096\n",
      "Epoch 39/50 - Loss: 0.8208 - Train Acc: 0.7091 - Test Acc: 0.7096\n",
      "Epoch 40/50 - Loss: 0.8234 - Train Acc: 0.7085 - Test Acc: 0.7099\n",
      "Epoch 41/50 - Loss: 0.8234 - Train Acc: 0.7089 - Test Acc: 0.7099\n",
      "Epoch 42/50 - Loss: 0.8227 - Train Acc: 0.7086 - Test Acc: 0.7100\n",
      "Epoch 43/50 - Loss: 0.8215 - Train Acc: 0.7086 - Test Acc: 0.7099\n",
      "Epoch 44/50 - Loss: 0.8206 - Train Acc: 0.7088 - Test Acc: 0.7101\n",
      "Epoch 45/50 - Loss: 0.8215 - Train Acc: 0.7092 - Test Acc: 0.7100\n",
      "Epoch 46/50 - Loss: 0.8212 - Train Acc: 0.7087 - Test Acc: 0.7102\n",
      "Epoch 47/50 - Loss: 0.8199 - Train Acc: 0.7088 - Test Acc: 0.7100\n",
      "Epoch 48/50 - Loss: 0.8208 - Train Acc: 0.7095 - Test Acc: 0.7101\n",
      "Epoch 49/50 - Loss: 0.8195 - Train Acc: 0.7089 - Test Acc: 0.7096\n",
      "Epoch 50/50 - Loss: 0.8204 - Train Acc: 0.7094 - Test Acc: 0.7098\n",
      "\n",
      "Final Test Accuracy: 0.7098\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Uncertain       0.71      1.00      0.83      6553\n",
      "       anger       0.00      0.00      0.00       167\n",
      "     disgust       0.00      0.00      0.00         9\n",
      "        fear       0.00      0.00      0.00       668\n",
      "         joy       0.00      0.00      0.00       232\n",
      "     neutral       0.00      0.00      0.00        12\n",
      "     sadness       0.38      0.01      0.01      1520\n",
      "    surprise       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.71      9230\n",
      "   macro avg       0.14      0.13      0.11      9230\n",
      "weighted avg       0.57      0.71      0.59      9230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "# Load your dataset from the CSV file\n",
    "data = pd.read_csv('emotion_data.csv')\n",
    "\n",
    "# Define the target variable and feature columns\n",
    "target_col = 'predicted_emotion'\n",
    "feature_cols = [\n",
    "    'sentiment_score', 'text_length', 'word_count', \n",
    "    'avg_word_length', 'stopword_count', \n",
    "    'first_person_pronoun_count', 'keyword_count'\n",
    "]\n",
    "\n",
    "# Select features (X) and target (y)\n",
    "X = data[feature_cols]\n",
    "y = data[target_col]\n",
    "\n",
    "# Print the first few rows to verify the data\n",
    "print(\"Selected Features:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget Variable:\")\n",
    "print(y.head())\n",
    "\n",
    "# Encode the target variable if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 2. Splitting and Scaling the Data\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler and scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader objects for batch training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3. Define the Updated Neural Network Model using PyTorch\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "model = MLP(input_dim, num_classes)\n",
    "\n",
    "# 4. Define Loss, Optimizer, and Training Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Lower learning rate for finer convergence\n",
    "num_epochs = 50\n",
    "\n",
    "# 5. Training the Model with Epoch-by-Epoch Monitoring\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "    \n",
    "    # Evaluate test accuracy\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "    test_acc = correct_test / total_test\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# 6. Final Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {np.mean(np.array(all_preds) == y_test):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f21026d-c96d-42f0-b838-07ea0ff49390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "   sentiment_score  text_length  word_count  avg_word_length  stopword_count  \\\n",
      "0           0.0000           10           3                3               1   \n",
      "1          -0.7269           61          10                6               3   \n",
      "2          -0.7351           75          14                5               5   \n",
      "3          -0.4215           59          11                5               3   \n",
      "4          -0.4939           66          14                4               8   \n",
      "\n",
      "   first_person_pronoun_count  keyword_count  \n",
      "0                           1              0  \n",
      "1                           0              0  \n",
      "2                           0              0  \n",
      "3                           1              0  \n",
      "4                           0              0  \n",
      "\n",
      "Target Variable:\n",
      "0     surprise\n",
      "1         fear\n",
      "2         fear\n",
      "3    Uncertain\n",
      "4         fear\n",
      "Name: predicted_emotion, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 0.9189 - Train Acc: 0.6983 - Test Loss: 0.8435 - Test Acc: 0.7101\n",
      "Epoch 10/100 - Train Loss: 0.8394 - Train Acc: 0.7091 - Test Loss: 0.8366 - Test Acc: 0.7096\n",
      "Epoch 20/100 - Train Loss: 0.8346 - Train Acc: 0.7092 - Test Loss: 0.8327 - Test Acc: 0.7103\n",
      "Epoch 30/100 - Train Loss: 0.8301 - Train Acc: 0.7090 - Test Loss: 0.8373 - Test Acc: 0.7100\n",
      "Epoch 40/100 - Train Loss: 0.8294 - Train Acc: 0.7091 - Test Loss: 0.8350 - Test Acc: 0.7105\n",
      "Epoch 50/100 - Train Loss: 0.8268 - Train Acc: 0.7091 - Test Loss: 0.8364 - Test Acc: 0.7101\n",
      "Epoch 60/100 - Train Loss: 0.8244 - Train Acc: 0.7090 - Test Loss: 0.8362 - Test Acc: 0.7096\n",
      "Epoch 70/100 - Train Loss: 0.8197 - Train Acc: 0.7098 - Test Loss: 0.8354 - Test Acc: 0.7094\n",
      "Epoch 80/100 - Train Loss: 0.8196 - Train Acc: 0.7099 - Test Loss: 0.8380 - Test Acc: 0.7093\n",
      "Epoch 90/100 - Train Loss: 0.8175 - Train Acc: 0.7097 - Test Loss: 0.8373 - Test Acc: 0.7090\n",
      "Epoch 100/100 - Train Loss: 0.8154 - Train Acc: 0.7090 - Test Loss: 0.8365 - Test Acc: 0.7092\n",
      "\n",
      "Final Test Accuracy: 0.7092\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Uncertain       0.71      1.00      0.83      6553\n",
      "       anger       0.00      0.00      0.00       167\n",
      "     disgust       0.00      0.00      0.00         9\n",
      "        fear       0.25      0.00      0.00       668\n",
      "         joy       0.00      0.00      0.00       232\n",
      "     neutral       0.00      0.00      0.00        12\n",
      "     sadness       0.35      0.01      0.02      1520\n",
      "    surprise       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.71      9230\n",
      "   macro avg       0.16      0.13      0.11      9230\n",
      "weighted avg       0.58      0.71      0.59      9230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "data = pd.read_csv('emotion_data.csv')\n",
    "target_col = 'predicted_emotion'\n",
    "feature_cols = [\n",
    "    'sentiment_score', 'text_length', 'word_count', \n",
    "    'avg_word_length', 'stopword_count', \n",
    "    'first_person_pronoun_count', 'keyword_count'\n",
    "]\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[target_col]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget Variable:\")\n",
    "print(y.head())\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 2. Splitting and Scaling the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader objects for batch training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3. Define the Updated Neural Network Model with Batch Normalization\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "model = MLP(input_dim, num_classes)\n",
    "\n",
    "# 4. Define Loss, Optimizer, and Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Lower learning rate for finer convergence\n",
    "\n",
    "# Scheduler to reduce LR when training loss plateaus\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# 5. Training the Model with Metrics Printed Every 10 Epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "    test_loss /= total_test\n",
    "    test_acc = correct_test / total_test\n",
    "\n",
    "    # Step the scheduler with the training loss\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "    # Print metrics every 10 epochs (and also for the first epoch)\n",
    "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# 6. Final Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {np.mean(np.array(all_preds) == y_test):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f6c388-0835-4478-8df1-e0a3b487c0ef",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7a21a83-b478-4e80-8c57-9d28467610f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "   sentiment_score  text_length  word_count  avg_word_length  stopword_count  \\\n",
      "0           0.0000           10           3                3               1   \n",
      "1          -0.7269           61          10                6               3   \n",
      "2          -0.7351           75          14                5               5   \n",
      "3          -0.4215           59          11                5               3   \n",
      "4          -0.4939           66          14                4               8   \n",
      "\n",
      "   first_person_pronoun_count  keyword_count  \n",
      "0                           1              0  \n",
      "1                           0              0  \n",
      "2                           0              0  \n",
      "3                           1              0  \n",
      "4                           0              0  \n",
      "\n",
      "Target Variable:\n",
      "0     surprise\n",
      "1         fear\n",
      "2         fear\n",
      "3    Uncertain\n",
      "4         fear\n",
      "Name: predicted_emotion, dtype: object\n",
      "Epoch 10/50 - Train Loss: 0.8313 - Train Acc: 0.7087 - Test Loss: 0.8380 - Test Acc: 0.7095\n",
      "Epoch 20/50 - Train Loss: 0.8241 - Train Acc: 0.7094 - Test Loss: 0.8396 - Test Acc: 0.7101\n",
      "Epoch 30/50 - Train Loss: 0.8208 - Train Acc: 0.7088 - Test Loss: 0.8383 - Test Acc: 0.7094\n",
      "Epoch 40/50 - Train Loss: 0.8171 - Train Acc: 0.7097 - Test Loss: 0.8439 - Test Acc: 0.7093\n",
      "Epoch 50/50 - Train Loss: 0.8152 - Train Acc: 0.7099 - Test Loss: 0.8442 - Test Acc: 0.7101\n",
      "\n",
      "Final Test Accuracy: 0.7101\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Uncertain       0.72      0.99      0.83      6553\n",
      "       anger       0.00      0.00      0.00       167\n",
      "     disgust       0.00      0.00      0.00         9\n",
      "        fear       0.50      0.02      0.03       668\n",
      "         joy       0.29      0.01      0.02       232\n",
      "     neutral       0.00      0.00      0.00        12\n",
      "     sadness       0.44      0.05      0.09      1520\n",
      "    surprise       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.71      9230\n",
      "   macro avg       0.24      0.13      0.12      9230\n",
      "weighted avg       0.62      0.71      0.61      9230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "data = pd.read_csv('emotion_data.csv')\n",
    "target_col = 'predicted_emotion'\n",
    "feature_cols = [\n",
    "    'sentiment_score', 'text_length', 'word_count', \n",
    "    'avg_word_length', 'stopword_count', \n",
    "    'first_person_pronoun_count', 'keyword_count'\n",
    "]\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[target_col]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget Variable:\")\n",
    "print(y.head())\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 2. Splitting and Scaling the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader objects for batch training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3. Define the CNN Model for Classification\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        # The input will be reshaped to (batch_size, 1, input_dim)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=2)\n",
    "        # Compute the output dimension after conv/pooling:\n",
    "        # If input_dim = 7, then:\n",
    "        # After conv1: 7 - 2 + 1 = 6, then pooling: floor(6/2)=3\n",
    "        # After conv2: 3 - 2 + 1 = 2. \n",
    "        # Flattened dimension = 64 * 2 = 128.\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input from (batch_size, input_dim) to (batch_size, 1, input_dim)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]  # should be 7\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "model = CNNClassifier(input_dim, num_classes)\n",
    "\n",
    "# 4. Define Loss, Optimizer, and Training Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "# 5. Training the CNN Model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "\n",
    "    # Evaluate on test set every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        running_loss_test = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss_test += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_test += (preds == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        test_loss = running_loss_test / total_test\n",
    "        test_acc = correct_test / total_test\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# 6. Final Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "final_accuracy = np.mean(np.array(all_preds) == y_test)\n",
    "print(f\"\\nFinal Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dffa25c-77f3-4268-87f7-f480467705a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "   sentiment_score  text_length  word_count  avg_word_length  stopword_count  \\\n",
      "0           0.0000           10           3                3               1   \n",
      "1          -0.7269           61          10                6               3   \n",
      "2          -0.7351           75          14                5               5   \n",
      "3          -0.4215           59          11                5               3   \n",
      "4          -0.4939           66          14                4               8   \n",
      "\n",
      "   first_person_pronoun_count  keyword_count  \n",
      "0                           1              0  \n",
      "1                           0              0  \n",
      "2                           0              0  \n",
      "3                           1              0  \n",
      "4                           0              0  \n",
      "\n",
      "Target Variable:\n",
      "0     surprise\n",
      "1         fear\n",
      "2         fear\n",
      "3    Uncertain\n",
      "4         fear\n",
      "Name: predicted_emotion, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 0.8445 - Train Acc: 0.7086 - Test Loss: 0.8369 - Test Acc: 0.7104\n",
      "Epoch 20/50 - Train Loss: 0.8372 - Train Acc: 0.7087 - Test Loss: 0.8410 - Test Acc: 0.7105\n",
      "Epoch 30/50 - Train Loss: 0.8308 - Train Acc: 0.7089 - Test Loss: 0.8345 - Test Acc: 0.7102\n",
      "Epoch 40/50 - Train Loss: 0.8280 - Train Acc: 0.7088 - Test Loss: 0.8341 - Test Acc: 0.7100\n",
      "Epoch 50/50 - Train Loss: 0.8238 - Train Acc: 0.7098 - Test Loss: 0.8345 - Test Acc: 0.7099\n",
      "\n",
      "Final Test Accuracy: 0.7099\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Uncertain       0.71      1.00      0.83      6553\n",
      "       anger       0.00      0.00      0.00       167\n",
      "     disgust       0.00      0.00      0.00         9\n",
      "        fear       0.00      0.00      0.00       668\n",
      "         joy       0.00      0.00      0.00       232\n",
      "     neutral       0.00      0.00      0.00        12\n",
      "     sadness       0.45      0.01      0.02      1520\n",
      "    surprise       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.71      9230\n",
      "   macro avg       0.15      0.13      0.11      9230\n",
      "weighted avg       0.58      0.71      0.59      9230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\annas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Tuning the CNN\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "data = pd.read_csv('emotion_data.csv')\n",
    "target_col = 'predicted_emotion'\n",
    "feature_cols = [\n",
    "    'sentiment_score', 'text_length', 'word_count', \n",
    "    'avg_word_length', 'stopword_count', \n",
    "    'first_person_pronoun_count', 'keyword_count'\n",
    "]\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[target_col]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget Variable:\")\n",
    "print(y.head())\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 2. Splitting and Scaling the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader objects for batch training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3. Define the Tuned CNN Model for Classification\n",
    "class TunedCNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(TunedCNNClassifier, self).__init__()\n",
    "        # Reshape input (batch_size, 1, input_dim)\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout_conv = nn.Dropout(0.3)\n",
    "        # Fully connected layers: Calculate flattened size:\n",
    "        # For input_dim = 7:\n",
    "        # After conv1: 7 - 2 + 1 = 6, then pooling: floor(6/2)=3.\n",
    "        # After conv2: 3 - 2 + 1 = 2, so flattened size = 128 * 2 = 256.\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.dropout_fc = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Reshape to (batch_size, 1, input_dim)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_conv(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]  # 7 features\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "model = TunedCNNClassifier(input_dim, num_classes)\n",
    "\n",
    "# 4. Define Loss, Optimizer, and Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "num_epochs = 50\n",
    "\n",
    "# 5. Training the Tuned CNN Model with Metrics Printed Every 10 Epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    running_loss_test = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss_test += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "    test_loss = running_loss_test / total_test\n",
    "    test_acc = correct_test / total_test\n",
    "\n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# 6. Final Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "final_accuracy = np.mean(np.array(all_preds) == y_test)\n",
    "print(f\"\\nFinal Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e48e75-3ab6-4d8f-a247-b46a817d33fd",
   "metadata": {},
   "source": [
    "### Comparison Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf00653-44cb-4baf-aea1-1e9e984b197b",
   "metadata": {},
   "source": [
    "An average F1-score of 0.71 suggests the models capture relevant patterns but may fall short for applications requiring higher precision and recall. This plateau indicates potential gaps in the feature set or modeling approach, as traditional models and neural networks show consistent but limited performance. The complexity of mental health classification may require more advanced text representations or contextual features. Modest improvements across iterations suggest challenges like class overlap and data quality. To enhance performance, exploring ensemble methods, refining feature engineering, and integrating domain-specific knowledge could be beneficial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
